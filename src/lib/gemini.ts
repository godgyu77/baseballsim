import { GoogleGenerativeAI } from '@google/generative-ai';
import { KBO_SYSTEM_LOGIC, KBO_INITIAL_DATA } from '../constants/prompts';
import { Team } from '../constants/TeamData';
import { Difficulty } from '../constants/GameConfig';
import { generateInitPromptFromTeam } from './promptGenerator';
import { retryRequest } from './retryUtils';
import { getInitialRosterForTeam } from './rosterFormatter';

export const GEMINI_MODEL = 'gemini-2.5-flash';

/**
 * [Context Caching] ìºì‹œëœ ì»¨í…ì¸ ì˜ ì´ë¦„(ID)ì„ ì €ì¥í•  ë³€ìˆ˜
 * API ë ˆë²¨ ìºì‹±ì„ ì‚¬ìš©í•˜ì—¬ System Instruction í† í° ë¹„ìš©ì„ ì ˆê°í•©ë‹ˆë‹¤.
 */
let activeCacheName: string | null = null;
let cacheCreationAttempted = false; // ìºì‹œ ìƒì„± ì‹œë„ ì—¬ë¶€ (ì¤‘ë³µ ì‹œë„ ë°©ì§€)

/**
 * [Cost Optimization] ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìºì‹œ (ë¡œì»¬ ë³€ìˆ˜)
 * ê°™ì€ API í‚¤ì— ëŒ€í•´ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ë¶ˆí•„ìš”í•œ ê°ì²´ ìƒì„±ì„ ë°©ì§€í•©ë‹ˆë‹¤.
 * 
 * âš ï¸ ì°¸ê³ : ì´ê²ƒì€ ë¡œì»¬ ë³€ìˆ˜ ì¬ì‚¬ìš©ì´ë©°, API ë ˆë²¨ Context Caching(cachedContent)ê³¼ëŠ” ë³„ê°œì…ë‹ˆë‹¤.
 */
const modelCache = new Map<string, any>();

/**
 * [Context Caching] ì„œë²„ ì‚¬ì´ë“œì—ì„œ ìºì‹œ ìƒì„± (Vercel API Route ì‚¬ìš©)
 * 
 * @param apiKey API í‚¤
 * @returns ìºì‹œ ì´ë¦„ ë˜ëŠ” null (ìƒì„± ì‹¤íŒ¨ ì‹œ)
 */
async function createCacheOnServer(apiKey: string): Promise<string | null> {
  try {
    console.log('[Context Caching] âš¡ ì„œë²„ì—ì„œ ìºì‹œ ìƒì„± ì‹œë„...');
    
    const response = await fetch('/api/cache/create', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ apiKey }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(`Server error: ${response.status} - ${errorData.message || 'Unknown error'}`);
    }

    const data = await response.json();
    
    // ë¬´ë£Œ í‹°ì–´ ì œí•œì¸ ê²½ìš° ëª…í™•í•˜ê²Œ ì²˜ë¦¬
    if (data.success === false && data.error === 'Free tier limit') {
      console.warn('[Context Caching] âš ï¸ ë¬´ë£Œ í‹°ì–´ ì œí•œ: Context Caching ì‚¬ìš© ë¶ˆê°€');
      console.warn('[Context Caching] ğŸ’¡ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš© (System Instruction ë§¤ë²ˆ ì „ì†¡)');
      return null; // Fallbackìœ¼ë¡œ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
    }
    
    if (data.success && data.cacheId) {
      console.log(`[Context Caching] âœ… ì„œë²„ì—ì„œ ìºì‹œ ìƒì„± ì„±ê³µ: ${data.cacheId}`);
      console.log(`[Context Caching] ìºì‹œ ë§Œë£Œ ì‹œê°„: ${new Date(data.expiresAt).toLocaleString()}`);
      return data.cacheId;
    }

    return null;
  } catch (error: any) {
    console.error('[Context Caching] âŒ ì„œë²„ ìºì‹œ ìƒì„± ì‹¤íŒ¨:', error);
    console.warn('[Context Caching] ğŸ’¡ Fallback: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš© (System Instruction ë§¤ë²ˆ ì „ì†¡)');
    return null;
  }
}

/**
 * [Context Caching] ë¸Œë¼ìš°ì € í™˜ê²½ì—ì„œ cachedContent ìƒì„± ì‹œë„ (Deprecated)
 * 
 * @deprecated ë¸Œë¼ìš°ì € í™˜ê²½ì—ì„œëŠ” ì‘ë™í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì„œë²„ ì‚¬ì´ë“œ ë°©ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.
 * @param genAI GoogleGenerativeAI ì¸ìŠ¤í„´ìŠ¤
 * @param apiKey API í‚¤
 * @returns ìºì‹œ ì´ë¦„ ë˜ëŠ” null (ìƒì„± ì‹¤íŒ¨ ì‹œ)
 */
async function tryCreateCachedContent(genAI: GoogleGenerativeAI, apiKey: string): Promise<string | null> {
  // [CRITICAL] ë¸Œë¼ìš°ì € í™˜ê²½ì—ì„œ cachedContent ìƒì„±ì€ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  // Google Gemini APIì˜ cachedContentëŠ” ì£¼ë¡œ ì„œë²„ ì‚¬ì´ë“œ(Node.js/Python)ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.
  // ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ ìƒì„±í•˜ë ¤ë©´ CORS ë° ë³´ì•ˆ ì •ì±…ì„ í†µê³¼í•´ì•¼ í•©ë‹ˆë‹¤.
  
  try {
    // [CHECK] SDKì—ì„œ cachedContent ìƒì„± ë©”ì„œë“œ í™•ì¸
    // @google/generative-ai SDK ë²„ì „ì— ë”°ë¼ APIê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    // ë°©ë²• 1: getGenerativeModelì„ í†µí•´ cachedContent ìƒì„± ì‹œë„
    const tempModel = genAI.getGenerativeModel({
      model: GEMINI_MODEL,
    });
    
    // [ATTEMPT] cachedContent ìƒì„± (SDK ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    // ì°¸ê³ : ìµœì‹  SDKì—ì„œëŠ” createCachedContentê°€ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ì— ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    if (typeof (tempModel as any).createCachedContent === 'function') {
      console.log('[Context Caching] âš¡ ë¸Œë¼ìš°ì €ì—ì„œ cachedContent ìƒì„± ì‹œë„...');
      
      const cache = await (tempModel as any).createCachedContent({
        model: GEMINI_MODEL,
        contents: [{
          role: 'system',
          parts: [{ text: KBO_SYSTEM_LOGIC }],
        }],
        ttlSeconds: 60 * 60, // 1ì‹œê°„ ìœ ì§€
      });
      
      if (cache && cache.name) {
        console.log(`[Context Caching] âœ… ìºì‹œ ìƒì„± ì„±ê³µ: ${cache.name}`);
        return cache.name;
      }
    }
    
    // ë°©ë²• 2: genAI ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì§ì ‘ ìƒì„± ì‹œë„
    if (typeof (genAI as any).createCachedContent === 'function') {
      console.log('[Context Caching] âš¡ genAIì—ì„œ cachedContent ìƒì„± ì‹œë„...');
      
      const cache = await (genAI as any).createCachedContent({
        model: GEMINI_MODEL,
        contents: [{
          role: 'system',
          parts: [{ text: KBO_SYSTEM_LOGIC }],
        }],
        ttlSeconds: 60 * 60,
      });
      
      if (cache && cache.name) {
        console.log(`[Context Caching] âœ… ìºì‹œ ìƒì„± ì„±ê³µ: ${cache.name}`);
        return cache.name;
      }
    }
    
    // ë°©ë²• 3: CachedContentManager ì‚¬ìš© ì‹œë„
    if (typeof (genAI as any).getCachedContentManager === 'function') {
      console.log('[Context Caching] âš¡ CachedContentManager ì‚¬ìš© ì‹œë„...');
      
      const manager = (genAI as any).getCachedContentManager();
      if (manager && typeof manager.create === 'function') {
        const cache = await manager.create({
          model: GEMINI_MODEL,
          contents: [{
            role: 'system',
            parts: [{ text: KBO_SYSTEM_LOGIC }],
          }],
          ttlSeconds: 60 * 60,
        });
        
        if (cache && cache.name) {
          console.log(`[Context Caching] âœ… ìºì‹œ ìƒì„± ì„±ê³µ: ${cache.name}`);
          return cache.name;
        }
      }
    }
    
    // ëª¨ë“  ë°©ë²• ì‹¤íŒ¨
    console.warn('[Context Caching] âš ï¸ ë¸Œë¼ìš°ì € í™˜ê²½ì—ì„œ cachedContent ìƒì„± ì‹¤íŒ¨: SDKì—ì„œ ì§€ì›í•˜ì§€ ì•Šê±°ë‚˜ CORS ì œí•œ');
    return null;
    
  } catch (error: any) {
    // [FALLBACK] ë¸Œë¼ìš°ì € í™˜ê²½ì—ì„œ cachedContent ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°
    console.warn('[Context Caching] âš ï¸ ë¸Œë¼ìš°ì € í™˜ê²½ì—ì„œ cachedContent ìƒì„± ë¶ˆê°€:', error.message);
    console.warn('[Context Caching] ğŸ’¡ í•´ê²°ì±…: ì„œë²„ ì‚¬ì´ë“œ(Node.js/Python)ì—ì„œ cachedContentë¥¼ ìƒì„±í•˜ê³ , ë¸Œë¼ìš°ì €ì—ì„œëŠ” ìºì‹œ ì´ë¦„ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.');
    return null;
  }
}

/**
 * [Cost Optimization] Gemini ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (Context Caching ì ìš©)
 * 
 * @param apiKey Gemini API í‚¤
 * @returns ìºì‹œëœ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” ìƒˆë¡œ ìƒì„±í•œ ì¸ìŠ¤í„´ìŠ¤
 */
export async function getGeminiModel(apiKey: string) {
  const genAI = new GoogleGenerativeAI(apiKey);
  
  // [Context Caching] 1. ì´ë¯¸ ìºì‹œê°€ ìƒì„±ë˜ì–´ ìˆë‹¤ë©´, í•´ë‹¹ ìºì‹œ IDë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ë²¼ìš´ ëª¨ë¸ ìƒì„±
  if (activeCacheName) {
    console.log(`[Context Caching] âœ… Using Active Cache: ${activeCacheName.substring(0, 20)}...`);
    const model = genAI.getGenerativeModel({
      model: GEMINI_MODEL,
      cachedContent: activeCacheName, // ìºì‹œëœ ì»¨í…ì¸  ì‚¬ìš© (System Instruction í† í° ë¹„ìš© 0ì›)
    });
    
    // ë¡œì»¬ ìºì‹œì—ë„ ì €ì¥ (ê°ì²´ ì¬ì‚¬ìš©)
    if (!modelCache.has(apiKey)) {
      modelCache.set(apiKey, model);
    }
    
    return model;
  }
  
  // [Context Caching] 2. ìºì‹œê°€ ì—†ë‹¤ë©´ ì„œë²„ì—ì„œ ìƒì„± ì‹œë„ (ìµœì´ˆ 1íšŒë§Œ)
  if (!cacheCreationAttempted) {
    cacheCreationAttempted = true;
    console.log('[Context Caching] âš¡ ì„œë²„ì—ì„œ ìºì‹œ ìƒì„± ì‹œë„...');
    
    // ì„œë²„ ì‚¬ì´ë“œ Context Caching ì‚¬ìš© (ê¶Œì¥)
    const cacheName = await createCacheOnServer(apiKey);
    
    if (cacheName) {
      // ìºì‹œ ìƒì„± ì„±ê³µ: ìºì‹œ ì´ë¦„ ì €ì¥
      activeCacheName = cacheName;
      
      // ìºì‹œëœ ì»¨í…ì¸ ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ìƒì„±
      const model = genAI.getGenerativeModel({
        model: GEMINI_MODEL,
        cachedContent: activeCacheName,
      });
      
      modelCache.set(apiKey, model);
      console.log('[Context Caching] âœ… Context Caching í™œì„±í™”: System Instruction í† í° ë¹„ìš© 0ì›');
      return model;
    } else {
      // ì„œë²„ ìºì‹œ ìƒì„± ì‹¤íŒ¨: ë¸Œë¼ìš°ì € ë°©ì‹ ì‹œë„ (Fallback)
      console.warn('[Context Caching] âš ï¸ ì„œë²„ ìºì‹œ ìƒì„± ì‹¤íŒ¨, ë¸Œë¼ìš°ì € ë°©ì‹ ì‹œë„...');
      const browserCacheName = await tryCreateCachedContent(genAI, apiKey);
      
      if (browserCacheName) {
        activeCacheName = browserCacheName;
        const model = genAI.getGenerativeModel({
          model: GEMINI_MODEL,
          cachedContent: activeCacheName,
        });
        modelCache.set(apiKey, model);
        console.log('[Context Caching] âœ… ë¸Œë¼ìš°ì €ì—ì„œ Context Caching í™œì„±í™”');
        return model;
      } else {
        // ëª¨ë“  ë°©ë²• ì‹¤íŒ¨: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
        console.warn('[Context Caching] âš ï¸ ëª¨ë“  ìºì‹œ ìƒì„± ë°©ë²• ì‹¤íŒ¨: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš© (System Instruction ë§¤ë²ˆ ì „ì†¡)');
      }
    }
  }
  
  // [Fallback] ìºì‹œ ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” ë¸Œë¼ìš°ì € í™˜ê²½ ì œí•œ: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
  // âš ï¸ ì£¼ì˜: ì´ê²ƒì€ ë¡œì»¬ ë³€ìˆ˜ ì¬ì‚¬ìš©ì´ë©°, API ë ˆë²¨ Context Caching(cachedContent)ì´ ì•„ë‹™ë‹ˆë‹¤.
  // System Instructionì€ ë§¤ ìš”ì²­ë§ˆë‹¤ í† í°ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.
  if (modelCache.has(apiKey)) {
    console.log('[Cost Optimization] ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìºì‹œì—ì„œ ì¬ì‚¬ìš© (ë¡œì»¬ ë³€ìˆ˜, API ë ˆë²¨ ìºì‹± ì•„ë‹˜):', apiKey.substring(0, 10) + '...');
    return modelCache.get(apiKey)!;
  }

  // [Cost Optimization] ìºì‹œì— ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•˜ê³  ìºì‹œì— ì €ì¥
  console.log('[Cost Optimization] ìƒˆ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ìºì‹± (ë¡œì»¬ ë³€ìˆ˜, API ë ˆë²¨ ìºì‹± ì•„ë‹˜):', apiKey.substring(0, 10) + '...');
  const model = genAI.getGenerativeModel({
    model: GEMINI_MODEL,
    systemInstruction: KBO_SYSTEM_LOGIC || 'ë‹¹ì‹ ì€ ì•¼êµ¬ ë§¤ë‹ˆì§€ë¨¼íŠ¸ ê²Œì„ì˜ ê²Œì„ë§ˆìŠ¤í„°ì…ë‹ˆë‹¤.',
  });
  
  // [Cost Optimization] ìºì‹œì— ì €ì¥í•˜ì—¬ ë‹¤ìŒ í˜¸ì¶œ ì‹œ ì¬ì‚¬ìš©
  // âš ï¸ ì°¸ê³ : ì‹¤ì œ API ë ˆë²¨ Context Caching(cachedContent)ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì„œë²„ ì‚¬ì´ë“œ êµ¬í˜„ì´ í•„ìš”í•©ë‹ˆë‹¤.
  modelCache.set(apiKey, model);
  
  return model;
}

/**
 * [Cost Optimization] ëª¨ë¸ ìºì‹œ ì´ˆê¸°í™” (API í‚¤ ë³€ê²½ ì‹œ ì‚¬ìš©)
 * 
 * @param apiKey ì œê±°í•  API í‚¤ (ì„ íƒì , ì—†ìœ¼ë©´ ì „ì²´ ìºì‹œ í´ë¦¬ì–´)
 */
export function clearModelCache(apiKey?: string) {
  if (apiKey) {
    modelCache.delete(apiKey);
    console.log('[Cost Optimization] íŠ¹ì • API í‚¤ì˜ ëª¨ë¸ ìºì‹œ ì œê±°:', apiKey.substring(0, 10) + '...');
  } else {
    modelCache.clear();
    console.log('[Cost Optimization] ì „ì²´ ëª¨ë¸ ìºì‹œ ì´ˆê¸°í™”');
  }
  
  // [Context Caching] ìºì‹œ ì´ë¦„ë„ ì´ˆê¸°í™”
  activeCacheName = null;
  cacheCreationAttempted = false;
  console.log('[Context Caching] ìºì‹œ ì´ë¦„ ì´ˆê¸°í™” ì™„ë£Œ');
}

/**
 * ê²Œì„ ì´ˆê¸°í™” ì‹œ ì´ˆê¸° ë°ì´í„°ë¥¼ Gemini APIì— ì „ì†¡í•˜ëŠ” í•¨ìˆ˜
 * [FIX] API History ê°•ì œ ì´ˆê¸°í™” (User First ê·œì¹™ ì¤€ìˆ˜)
 * 
 * âš ï¸ CRITICAL: ì´ í•¨ìˆ˜ëŠ” React ìƒíƒœ(messages)ì— ì €ì¥ëœ ì´ì „ AI ì‘ë‹µì„ ì ˆëŒ€ historyë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
 * Gemini API ê·œì¹™: "First content should be with role 'user', got model" ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´
 * historyë¥¼ ë¬´ì¡°ê±´ ë¹ˆ ë°°ì—´ []ë¡œ í•˜ë“œì½”ë”©í•©ë‹ˆë‹¤.
 * 
 * @param apiKey Gemini API í‚¤
 * @param difficulty ì‚¬ìš©ìê°€ ì„ íƒí•œ ë‚œì´ë„
 * @param selectedTeam ì‚¬ìš©ìê°€ ì„ íƒí•œ íŒ€ ì •ë³´
 * @param _ignoredHistory history ì¸ìëŠ” ë°›ë”ë¼ë„ ë¬´ì‹œí•©ë‹ˆë‹¤. (API ì—ëŸ¬ ë°©ì§€ìš©)
 * @returns AIì˜ ì´ˆê¸° ì‘ë‹µ í…ìŠ¤íŠ¸
 */
export async function initializeGameWithData(
  apiKey: string,
  difficulty: Difficulty,
  selectedTeam: Team,
  // history ì¸ìëŠ” ë°›ë”ë¼ë„ ë¬´ì‹œí•©ë‹ˆë‹¤. (API ì—ëŸ¬ ë°©ì§€ìš©)
  _ignoredHistory: any[] = []
): Promise<string> {
  // ì•ˆì „ ì¥ì¹˜: ë°ì´í„° ê¸¸ì´ í™•ì¸
  console.log("Data Length:", KBO_INITIAL_DATA.length);
  
  if (KBO_INITIAL_DATA.length < 5000) {
    console.error("âŒ ë¡œìŠ¤í„° ë°ì´í„° ëˆ„ë½ë¨!");
    throw new Error("ë¡œìŠ¤í„° ë°ì´í„°ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„° ê¸¸ì´ê°€ 5,000ì ë¯¸ë§Œì…ë‹ˆë‹¤.");
  }
  
  // Gemini ëª¨ë¸ ì´ˆê¸°í™”
  const model = await getGeminiModel(apiKey);
  
  // [CRITICAL FIX] API History ê°•ì œ ì´ˆê¸°í™” (User First ê·œì¹™ ì¤€ìˆ˜)
  // í™”ë©´ì— ë– ìˆëŠ” í…ìŠ¤íŠ¸(Model Role)ê°€ historyì— ì„ì´ë©´ ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.
  // ë”°ë¼ì„œ ë¬´ì¡°ê±´ ë¹ˆ ë°°ì—´ []ë¡œ ì‹œì‘í•˜ì—¬, ì•„ë˜ì˜ sendMessageê°€ 'ì²« ë²ˆì§¸ User ë©”ì‹œì§€'ê°€ ë˜ê²Œ í•©ë‹ˆë‹¤.
  // âš ï¸ ì£¼ì˜: _ignoredHistory ì¸ìëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¬´ì¡°ê±´ ë¹ˆ ë°°ì—´ []ì„ í•˜ë“œì½”ë”©í•©ë‹ˆë‹¤.
  const chat = model.startChat({
    history: [], // [CRITICAL] ë³€ìˆ˜ë¥¼ ë„£ì§€ ë§ê³  ë¹ˆ ë°°ì—´ì„ ì§ì ‘ í•˜ë“œì½”ë”©í•  ê²ƒ!
    generationConfig: {
      maxOutputTokens: 16384, // [FIX] ë¡œìŠ¤í„° ë°ì´í„° ì™„ê²°ì„± ë³´ì¥: 8000 -> 16384ë¡œ ì¦ê°€ (íˆ¬ìˆ˜+íƒ€ì ì „ì²´ ë°ì´í„° ìˆ˜ìš©)
    },
  });
  
  // [NEW] ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ ì‚¬ìš©
  // ì´ˆê¸° ì‹œì„¤ ë ˆë²¨ì€ ëª¨ë‘ 1ë¡œ ì‹œì‘
  const initPromptText = generateInitPromptFromTeam(selectedTeam, difficulty);
  
  // [TOKEN OPTIMIZATION] ì„ íƒëœ íŒ€ì˜ ë¡œìŠ¤í„°ë§Œ ì „ì†¡ (ì „ì²´ ë¡œìŠ¤í„° ì œê±°)
  const selectedTeamRoster = getInitialRosterForTeam(selectedTeam.fullName);
  
  // Initial Dataì™€ í”„ë¡¬í”„íŠ¸ ê²°í•© (ì„ íƒëœ íŒ€ë§Œ)
  const initPrompt = `${selectedTeamRoster}

${initPromptText}

[SYSTEM INSTRUCTION: INITIALIZATION OVERRIDE]
1. The user has ALREADY selected the difficulty and team via the UI.
2. DO NOT output "Welcome" text or ask for difficulty.
3. DO NOT ask "ì–´ë–¤ ë‚œì´ë„ë¡œ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?" or "ë‚œì´ë„ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”" or similar questions.
4. IMMEDIATELY assume the role of the GM/Assistant.
5. START THE GAME IMMEDIATELY with the <STATUS> dashboard for 2026-01-01 (2026ë…„ 1ì›” 1ì£¼ì°¨), and <NEWS> tag right now.
6. Output <OPTIONS> tag with game action buttons (ì¼ì • ì§„í–‰, ë¡œìŠ¤í„° í™•ì¸, etc.) immediately.
7. Start directly with the game simulation. Skip all introductory steps and go directly to the main game screen.`;
  
  // [Auto-Retry] ì´ˆê¸° ë°ì´í„° ì „ì†¡ (ì¬ì‹œë„ ë¡œì§ ì ìš©)
  // ì´ê²ƒì´ ì²« ë²ˆì§¸ User ë©”ì‹œì§€ê°€ ë©ë‹ˆë‹¤
  const result = await retryRequest(
    async () => {
      const messageResult = await chat.sendMessage(initPrompt);
      const messageResponse = await messageResult.response;
      return messageResponse.text();
    },
    {
      maxRetries: 3,
      onRetry: (attempt, error) => {
        console.warn(`[Auto-Retry] ê²Œì„ ì´ˆê¸°í™” ì¬ì‹œë„ ${attempt}/3:`, error);
      },
    }
  );
  
  return result;
}
